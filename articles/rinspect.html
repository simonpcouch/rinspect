<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Getting started with rinspect • rinspect</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Getting started with rinspect">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">rinspect</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9001</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/rinspect.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/simonpcouch/rinspect/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Getting started with rinspect</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/simonpcouch/rinspect/blob/main/vignettes/rinspect.Rmd" class="external-link"><code>vignettes/rinspect.Rmd</code></a></small>
      <div class="d-none name"><code>rinspect.Rmd</code></div>
    </div>

    
    
<p>At their core, LLM evals are composed of three pieces:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Datasets</strong> contain a set of labelled samples.
Datasets are just a tibble with columns <code>input</code> and
<code>target</code>, where <code>input</code> is a prompt and
<code>target</code> is either literal value(s) or grading guidance.</li>
<li>
<strong>Solvers</strong> evaluate the <code>input</code> in the
dataset and produce a final result (hopefully) approximating
<code>target</code>. In rinspect, the simplest solver is just an ellmer
chat
(e.g. <code>ellmer::chat_anthropic(model = "claude-3-7-sonnet-latest")</code>)
wrapped in <code><a href="../reference/generate.html">generate()</a></code>,
i.e. <code>generate(ellmer::chat_anthropic(model = "claude-3-7-sonnet-latest")</code>),
which will call the Chat object’s <code>$chat()</code> method and return
whatever it returns.</li>
<li>
<strong>Scorers</strong> evaluate the final output of solvers. They
may use text comparisons, model grading, or other custom schemes to
determine how well the solver approximated the <code>target</code> based
on the <code>input</code>.</li>
</ol>
<p>This vignette will explore these three components using
<code>are</code>, an example dataset that ships with the package.</p>
<p>First, load the required packages:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/simonpcouch/rinspect" class="external-link">rinspect</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ellmer.tidyverse.org" class="external-link">ellmer</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="an-r-eval-dataset">An R eval dataset<a class="anchor" aria-label="anchor" href="#an-r-eval-dataset"></a>
</h2>
<p>From the <code>are</code> docs:</p>
<blockquote>
<p>An R Eval is a dataset of challenging R coding problems. Each
<code>input</code> is a question about R code which could be solved on
first-read only by human experts and, with a chance to read
documentation and run some code, by fluent data scientists. Solutions
are in <code>target</code> and enable a fluent data scientist to
evaluate whether the solution deserves full, partial, or no credit.</p>
</blockquote>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">are</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Rows: 26</span></span>
<span><span class="co">#&gt; Columns: 7</span></span>
<span><span class="co">#&gt; $ title     <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "after-stat-bar-heights"<span style="color: #949494;">, </span>"conditional-grouped-summary"<span style="color: #949494;">, </span>"co…</span></span>
<span><span class="co">#&gt; $ input     <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "This bar chart shows the count of different cuts of diamond…</span></span>
<span><span class="co">#&gt; $ target    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "Preferably: \n\n```\nggplot(data = diamonds) + \n  geom_bar…</span></span>
<span><span class="co">#&gt; $ domain    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "Data analysis"<span style="color: #949494;">, </span>"Data analysis"<span style="color: #949494;">, </span>"Data analysis"<span style="color: #949494;">, </span>"Programm…</span></span>
<span><span class="co">#&gt; $ task      <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "New code"<span style="color: #949494;">, </span>"New code"<span style="color: #949494;">, </span>"New code"<span style="color: #949494;">, </span>"Debugging"<span style="color: #949494;">, </span>"New code"<span style="color: #949494;">,</span>…</span></span>
<span><span class="co">#&gt; $ source    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "https://jrnold.github.io/r4ds-exercise-solutions/data-visua…</span></span>
<span><span class="co">#&gt; $ knowledge <span style="color: #949494; font-style: italic;">&lt;list&gt;</span> "tidyverse"<span style="color: #949494;">, </span>"tidyverse"<span style="color: #949494;">, </span>"tidyverse"<span style="color: #949494;">, </span>"r-lib"<span style="color: #949494;">, </span>"tidyverse"…</span></span></code></pre>
<p>At a high level:</p>
<ul>
<li>
<code>title</code>: A unique identifier for the problem.</li>
<li>
<code>input</code>: The question to be answered.</li>
<li>
<code>target</code>: The solution, often with a description of
notable features of a correct solution.</li>
<li>
<code>domain</code>, <code>task</code>, and <code>knowledge</code>
are pieces of metadata describing the kind of R coding challenge.</li>
<li>
<code>source</code>: Where the problem came from, as a URL. Many of
these coding problems are adapted “from the wild” and include the kinds
of context usually available to those answering questions.</li>
</ul>
<p>For the purposes of actually carrying out the initial evaluation,
we’re specifically interested in the <code>input</code> and
<code>target</code> columns. Let’s print out the first entry in full so
you can get a taste of a typical problem in this dataset:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">are</span><span class="op">$</span><span class="va">input</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; This bar chart shows the count of different cuts of diamonds, and each</span></span>
<span><span class="co">#&gt; bar is stacked and filled according to clarity:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(mapping = aes(x = cut, fill = clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Could you change this code so that the proportion of diamonds with a</span></span>
<span><span class="co">#&gt; given cut corresponds to the bar height and not the count? Each bar</span></span>
<span><span class="co">#&gt; should still be filled according to clarity.</span></span></code></pre>
<p>Here’s the suggested solution:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">are</span><span class="op">$</span><span class="va">target</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Preferably:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(aes(x = cut, y = after_stat(count) / sum(after_stat(count)),</span></span>
<span><span class="co">#&gt; fill = clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0, but</span></span>
<span><span class="co">#&gt; it still works:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(aes(x = cut, y = ..count.. / sum(..count..), fill = clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Simply setting `position = "fill" will result in each bar having a</span></span>
<span><span class="co">#&gt; height of 1 and is not correct.</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="creating-and-evaluating-a-task">Creating and evaluating a task<a class="anchor" aria-label="anchor" href="#creating-and-evaluating-a-task"></a>
</h2>
<p>LLM evaluation with rinspect happens in two main steps:</p>
<ol style="list-style-type: decimal">
<li>Use <code>Task$new()</code> to situate a dataset, solver, and scorer
in a <code>Task</code>.</li>
</ol>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">are_task</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Task.html">Task</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  dataset <span class="op">=</span> <span class="va">are</span>,</span>
<span>  solver <span class="op">=</span> <span class="fu"><a href="../reference/generate.html">generate</a></span><span class="op">(</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_anthropic.html" class="external-link">chat_anthropic</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"claude-3-7-sonnet-latest"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  scorer <span class="op">=</span> <span class="fu"><a href="../reference/scorer_model.html">model_graded_qa</a></span><span class="op">(</span>partial_credit <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  name <span class="op">=</span> <span class="st">"An R Eval"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">are_task</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Use <code>Task$eval()</code> to evaluate the solver, evaluate the
scorer, and then explore a persistent log of the results in the
interactive Inspect log viewer.</li>
</ol>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">are_task</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>After evaluation, the task contains information from the solving and
scoring steps. Here’s what the model responded to that first question
with:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">are_task</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">result</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; # Converting Count to Proportion in a Diamond Cut Bar Chart</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; To change the bar chart from showing counts to showing proportions</span></span>
<span><span class="co">#&gt; (where each bar represents the proportion of diamonds with a given</span></span>
<span><span class="co">#&gt; cut), I need to modify the code to use proportions instead of counts</span></span>
<span><span class="co">#&gt; while still filling by clarity.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Here's the modified code:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ```r</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1, fill =</span></span>
<span><span class="co">#&gt; clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; In this modification:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1. `y = ..prop..` changes the y-axis to show proportions instead of</span></span>
<span><span class="co">#&gt; counts</span></span>
<span><span class="co">#&gt; 2. `group = 1` ensures the proportions are calculated relative to the</span></span>
<span><span class="co">#&gt; entire dataset (so each bar will show the proportion of all diamonds</span></span>
<span><span class="co">#&gt; that have a particular cut)</span></span>
<span><span class="co">#&gt; 3. The `fill = clarity` is maintained to preserve the stacking by</span></span>
<span><span class="co">#&gt; clarity within each cut</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; If you want each bar to have the same height (with each representing</span></span>
<span><span class="co">#&gt; 100% of diamonds within that cut category), with the fill showing the</span></span>
<span><span class="co">#&gt; proportion of clarity within each cut, you could use:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ```r</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The `position = "fill"` parameter standardizes each bar to the same</span></span>
<span><span class="co">#&gt; height, effectively showing the proportion of each clarity within each</span></span>
<span><span class="co">#&gt; cut.</span></span></code></pre>
<p>The task also contains score information from the scoring step. We’ve
used <code><a href="../reference/scorer_model.html">model_graded_qa()</a></code> as our scorer, which uses another
model to evaluate the quality of our solver’s solutions against the
reference solutions in the <code>target</code> column.
<code><a href="../reference/scorer_model.html">model_graded_qa()</a></code> is a model-graded scorer provided by the
package. This step compares Claude’s solutions against the reference
solutions in the <code>target</code> column, assigning a score to each
solution using another model. That score is either <code>1</code> or
<code>0</code>, though since we’ve set
<code>partial_credit = TRUE</code>, the model can also choose to allot
the response <code>.5</code>. rinspect will use the same model that
generated the final response as the model to score solutions.</p>
<p>Hold up, though—we’re using an LLM to generate responses to
questions, and then using the LLM to grade those responses?</p>
<p><img src="https://cdn-useast1.kapwing.com/static/templates/3-spiderman-pointing-meme-template-full-ca8f27e0.webp" alt="The meme of 3 spiderman pointing at each other."></p>
<p>This technique is called “model grading” or “LLM-as-a-judge.” Done
correctly, model grading is an effective and scalable solution to
scoring. That said, it’s not without its faults. Here’s what the grading
model thought of the response:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">are_task</span><span class="op">$</span><span class="va">samples</span><span class="op">$</span><span class="va">scorer_chat</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">last_turn</span><span class="op">(</span><span class="op">)</span><span class="op">@</span><span class="va">text</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; I need to assess whether the submission meets the criterion for showing</span></span>
<span><span class="co">#&gt; the proportion of diamonds with a given cut as the bar height while</span></span>
<span><span class="co">#&gt; still filling by clarity.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The criterion specifies that the correct approach is to use:</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(aes(x = cut, y = after_stat(count) / sum(after_stat(count)),</span></span>
<span><span class="co">#&gt; fill = clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; Or the deprecated but still functioning version:</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; ggplot(data = diamonds) +</span></span>
<span><span class="co">#&gt; geom_bar(aes(x = cut, y = ..count.. / sum(..count..), fill = clarity))</span></span>
<span><span class="co">#&gt; ```</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The submission offers two approaches:</span></span>
<span><span class="co">#&gt; 1. First approach uses `y = ..prop.., group = 1` which is close to the</span></span>
<span><span class="co">#&gt; requested solution but doesn't precisely calculate the proportion of</span></span>
<span><span class="co">#&gt; each cut in the total dataset as required.</span></span>
<span><span class="co">#&gt; 2. Second approach uses `position = "fill"` which the criterion</span></span>
<span><span class="co">#&gt; explicitly identifies as incorrect since it would make each bar have a</span></span>
<span><span class="co">#&gt; height of 1, showing proportions within each cut rather than the</span></span>
<span><span class="co">#&gt; proportion of each cut in the total dataset.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; The submission does attempt to solve the problem and includes the</span></span>
<span><span class="co">#&gt; deprecated `..prop..` notation, showing understanding of the general</span></span>
<span><span class="co">#&gt; concept. However, neither of the proposed solutions correctly</span></span>
<span><span class="co">#&gt; implements what's specified in the criterion. The first solution is</span></span>
<span><span class="co">#&gt; closer but doesn't correctly calculate proportions across the entire</span></span>
<span><span class="co">#&gt; dataset, and the second is explicitly noted as incorrect in the</span></span>
<span><span class="co">#&gt; criterion.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; GRADE: P</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="analyzing-the-results">Analyzing the results<a class="anchor" aria-label="anchor" href="#analyzing-the-results"></a>
</h2>
<p>Especially the first few times you run an eval, you’ll want to
inspect (ha!) its results closely. The rinspect package ships with an
app, the Inspect log viewer, that allows you to drill down into the
solutions and grading decisions from each model for each sample. In the
first couple runs, you’ll likely find revisions you can make to your
grading guidance in <code>target</code> that align model responses with
your intent.</p>
<iframe src="../example-logs/rinspect/index.html" width="100%" height="600px" style="border-radius: 10px; box-shadow: 0 5px 10px rgba(0, 0, 0, 0.3);"></iframe>
<p><br></p>
<p>Under the hood, when you call <code>task$eval()</code>, results are
written to a <code>.json</code> file that the Inspect log viewer can
read. The Task object automatically launches the viewer when you call
<code>task$eval()</code> in an interactive session. You can also view
results any time with <code>are_task$view()</code>. You can explore this
eval above (on the package’s pkgdown site).</p>
<p>For a cursory analysis, we can start off by visualizing correct
vs. partially correct vs. incorrect answers:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">are_task_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/inspect_bind.html">inspect_bind</a></span><span class="op">(</span><span class="va">are_task</span><span class="op">)</span></span>
<span></span>
<span><span class="va">are_task_data</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 28 × 4</span></span></span>
<span><span class="co">#&gt;    task        id score metadata         </span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;ord&gt;</span> <span style="color: #949494; font-style: italic;">&lt;list&gt;</span>           </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> are_task     1 P     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> are_task     2 C     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> are_task     3 P     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> are_task     4 P     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> are_task     5 I     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> are_task     6 C     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> are_task     7 I     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> are_task     8 I     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> are_task     9 I     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> are_task    10 P     <span style="color: #949494;">&lt;tibble [1 × 11]&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 18 more rows</span></span></span>
<span></span>
<span><span class="va">are_task_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">score</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_bar</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="rinspect_files/figure-html/plot-1-1.png" alt="A ggplot2 bar plot, showing Claude was correct most of the time." width="700"></p>
<p>Claude answered fully correctly in 12 out of 28 samples, and
partially correctly 10 times.For me, this leads to all sorts of
questions:</p>
<ul>
<li>Are there any models that are cheaper than Claude that would do just
as well? Or even a local model?</li>
<li>Are there other models available that would do better out of the
box?</li>
<li>Would Claude do better if I allow it to “reason” briefly before
answering?</li>
<li>Would Claude do better if I gave it tools that’d allow it to peruse
documentation and/or run R code before answering? (See <a href="https://posit-dev.github.io/btw/reference/btw_register_tools.html" class="external-link"><code>btw::btw_register_tools()</code></a>
if you’re interested in this.)</li>
</ul>
<p>These questions can be explored by evaluating Tasks against different
solvers and scorers. For example, to compare Claude’s performance with
OpenAI’s GPT-4o, we just need to clone the object and then run
<code>$eval()</code> with a different solver <code>chat</code>:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">are_task_openai</span> <span class="op">&lt;-</span> <span class="va">are_task</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">are_task_openai</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span>solver_chat <span class="op">=</span> <span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_openai.html" class="external-link">chat_openai</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"gpt-4o"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Any arguments to solving or scoring functions can be passed directly
to <code>$eval()</code>, allowing for quickly evaluating tasks across
several parameterizations.</p>
<p>Using this data, we can quickly juxtapose those evaluation
results:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">are_task_eval</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="../reference/inspect_bind.html">inspect_bind</a></span><span class="op">(</span><span class="va">are_task</span>, <span class="va">are_task_openai</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span></span>
<span>    task <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html" class="external-link">if_else</a></span><span class="op">(</span><span class="va">task</span> <span class="op">==</span> <span class="st">"are_task"</span>, <span class="st">"Claude"</span>, <span class="st">"GPT-4o"</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html" class="external-link">rename</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">task</span><span class="op">)</span></span>
<span></span>
<span><span class="va">are_task_eval</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">score</span>, fill <span class="op">=</span> <span class="va">model</span>, group <span class="op">=</span> <span class="va">model</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="st">"dodge"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_brewer.html" class="external-link">scale_fill_brewer</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"qual"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"bottom"</span><span class="op">)</span></span></code></pre></div>
<p><img src="rinspect_files/figure-html/unnamed-chunk-4-1.png" width="700"></p>
<p>Is this difference in performance just a result of noise, though? We
can supply the scores to an ordinal regression model to answer this
question.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">MASS</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'MASS'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:dplyr':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     select</span></span>
<span></span>
<span><span class="va">are_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/polr.html" class="external-link">polr</a></span><span class="op">(</span><span class="va">score</span> <span class="op">~</span> <span class="va">model</span>, data <span class="op">=</span> <span class="va">are_task_eval</span><span class="op">)</span></span>
<span></span>
<span><span class="va">are_mod</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; polr(formula = score ~ model, data = are_task_eval)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; modelGPT-4o </span></span>
<span><span class="co">#&gt;  -0.3322794 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Intercepts:</span></span>
<span><span class="co">#&gt;        I|P        P|C </span></span>
<span><span class="co">#&gt; -1.2706034  0.2732442 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual Deviance: 120.6603 </span></span>
<span><span class="co">#&gt; AIC: 126.6603</span></span></code></pre></div>
<p>The coefficient for <code>model == "GPT-4o"</code> is -0.332,
indicating that GPT-4o tends to be associated with lower grades. If a
95% confidence interval for this coefficient contains zero, we can
conclude that there is not sufficient evidence to reject the null
hypothesis that the difference between GPT-4o and Claude’s performance
on this eval is zero at the 0.05 significance level.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">are_mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; Waiting for profiling to be done...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Re-fitting to get Hessian</span></span>
<span><span class="co">#&gt;     2.5 %    97.5 % </span></span>
<span><span class="co">#&gt; -1.314314  0.637910</span></span></code></pre></div>
<div class="callout-note">
<p>If we had evaluated this model across multiple epochs,
<code>samples$epoch</code> could become a “nuisance parameter” in a
mixed model.</p>
</div>
<p>This vignette demonstrated the simplest possible evaluation based on
the <code>are</code> dataset. If you’re interested in carrying out more
advanced evals, check out the other vignettes in this package!</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Simon Couch, Posit Software, PBC.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
