<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Creating and evaluating tasks — Task • vitals</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_Pro-0.4.10/font.css" rel="stylesheet"><link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Creating and evaluating tasks — Task"><meta name="description" content="Evaluation Tasks provide a flexible data structure for evaluating LLM-based
tools.
Datasets contain a set of labelled samples. Datasets are just a
tibble with columns input and target, where input is a prompt
and target is either literal value(s) or grading guidance.
Solvers evaluate the input in the dataset and produce a final result.
Scorers evaluate the final output of solvers. They may use text
comparisons (like detect_match()), model grading (like
model_graded_qa()), or other custom schemes.


The usual flow of LLM evaluation with Tasks calls $new() and then $eval().
$eval() just calls $solve(), $score(), $measure(), $log(),
and $view() in order. The remaining methods are generally only
recommended for expert use."><meta property="og:description" content="Evaluation Tasks provide a flexible data structure for evaluating LLM-based
tools.
Datasets contain a set of labelled samples. Datasets are just a
tibble with columns input and target, where input is a prompt
and target is either literal value(s) or grading guidance.
Solvers evaluate the input in the dataset and produce a final result.
Scorers evaluate the final output of solvers. They may use text
comparisons (like detect_match()), model grading (like
model_graded_qa()), or other custom schemes.


The usual flow of LLM evaluation with Tasks calls $new() and then $eval().
$eval() just calls $solve(), $score(), $measure(), $log(),
and $view() in order. The remaining methods are generally only
recommended for expert use."><meta property="og:image" content="https://vitals.tidyverse.org/logo.png"><script defer data-domain="vitals.tidyverse.org,all.tidyverse.org" src="https://plausible.io/js/plausible.js"></script></head><body>
    <a href="#container" class="visually-hidden-focusable">Skip to content</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-none" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">vitals</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Unreleased version">0.0.0.9002</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/vitals.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/solvers.html">Custom solvers and tool calling</a></li>
    <li><a class="dropdown-item" href="../articles/writing-your-own.html">Writing your own evals for your LLM product</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tidyverse/vitals/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic" id="container">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Creating and evaluating tasks</h1>
      <small class="dont-index">Source: <a href="https://github.com/tidyverse/vitals/blob/main/R/task.R" class="external-link"><code>R/task.R</code></a></small>
      <div class="d-none name"><code>Task.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Evaluation <code>Task</code>s provide a flexible data structure for evaluating LLM-based
tools.</p><ol><li><p><strong>Datasets</strong> contain a set of labelled samples. Datasets are just a
tibble with columns <code>input</code> and <code>target</code>, where <code>input</code> is a prompt
and <code>target</code> is either literal value(s) or grading guidance.</p></li>
<li><p><strong>Solvers</strong> evaluate the <code>input</code> in the dataset and produce a final result.</p></li>
<li><p><strong>Scorers</strong> evaluate the final output of solvers. They may use text
comparisons (like <code><a href="scorer_detect.html">detect_match()</a></code>), model grading (like
<code><a href="scorer_model.html">model_graded_qa()</a></code>), or other custom schemes.</p></li>
</ol><p><strong>The usual flow of LLM evaluation with Tasks calls <code>$new()</code> and then <code>$eval()</code>.</strong>
<code>$eval()</code> just calls <code>$solve()</code>, <code>$score()</code>, <code>$measure()</code>, <code>$log()</code>,
and <code>$view()</code> in order. The remaining methods are generally only
recommended for expert use.</p>
    </div>


    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="generate.html">generate()</a></code> for the simplest possible solver, and
<a href="scorer_model.html">scorer_model</a> and <a href="scorer_detect.html">scorer_detect</a> for two built-in approaches to
scoring.</p></div>
    </div>
    <div class="section level2">
    <h2 id="public-fields">Public fields<a class="anchor" aria-label="anchor" href="#public-fields"></a></h2>
    <p></p><div class="r6-fields"><dl><dt><code>dir</code></dt>
<dd><p>The directory where evaluation logs will be written to. Defaults
to <code><a href="vitals_log_dir.html">vitals_log_dir()</a></code>.</p></dd>


<dt><code>metrics</code></dt>
<dd><p>A named vector of metric values resulting from <code>$measure()</code>
(called inside of <code>$eval()</code>). Will be <code>NULL</code> if metrics have yet to
be applied.</p></dd>


</dl><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a></h2>

<div class="section">
<h3 id="public-methods">Public methods<a class="anchor" aria-label="anchor" href="#public-methods"></a></h3>

<ul><li><p><a href="#method-Task-new"><code>Task$new()</code></a></p></li>
<li><p><a href="#method-Task-eval"><code>Task$eval()</code></a></p></li>
<li><p><a href="#method-Task-get_samples"><code>Task$get_samples()</code></a></p></li>
<li><p><a href="#method-Task-solve"><code>Task$solve()</code></a></p></li>
<li><p><a href="#method-Task-score"><code>Task$score()</code></a></p></li>
<li><p><a href="#method-Task-measure"><code>Task$measure()</code></a></p></li>
<li><p><a href="#method-Task-log"><code>Task$log()</code></a></p></li>
<li><p><a href="#method-Task-view"><code>Task$view()</code></a></p></li>
<li><p><a href="#method-Task-set_solver"><code>Task$set_solver()</code></a></p></li>
<li><p><a href="#method-Task-set_scorer"><code>Task$set_scorer()</code></a></p></li>
<li><p><a href="#method-Task-set_metrics"><code>Task$set_metrics()</code></a></p></li>
<li><p><a href="#method-Task-get_cost"><code>Task$get_cost()</code></a></p></li>
<li><p><a href="#method-Task-clone"><code>Task$clone()</code></a></p></li>
</ul></div><p></p><hr><a id="method-Task-new"></a><div class="section">
<h3 id="method-new-">Method <code>new()</code><a class="anchor" aria-label="anchor" href="#method-new-"></a></h3>
<p>The typical flow of LLM evaluation with vitals tends to involve first
calling this method and then <code>$eval()</code> on the resulting object.</p><div class="section">
<h4 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va"><a href="../reference/Task.html">Task</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  <span class="va">dataset</span>,</span>
<span>  <span class="va">solver</span>,</span>
<span>  <span class="va">scorer</span>,</span>
<span>  metrics <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epochs <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  name <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/deparse.html" class="external-link">deparse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/substitute.html" class="external-link">substitute</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  dir <span class="op">=</span> <span class="fu"><a href="../reference/vitals_log_dir.html">vitals_log_dir</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h4>
<p></p><div class="arguments"><dl><dt><code>dataset</code></dt>
<dd><p>A tibble with, minimally, columns <code>input</code> and <code>target</code>.</p></dd>


<dt><code>solver</code></dt>
<dd><p>A function that takes a vector of inputs from the
dataset's <code>input</code> column as its first argument and determines values
approximating <code>dataset$target</code>. Its return value must be a list with
the following elements:</p><ul><li><p><code>result</code> - A character vector of the final responses, with the same length
as <code>dataset$input</code>.</p></li>
<li><p><code>solver_chat</code> - A list of ellmer Chat objects that were used to solve
each input, also with the same length as <code>dataset$input</code>.</p></li>
</ul><p>Additional output elements can be included in a slot <code>solver_metadata</code> that
has the same length as <code>dataset$input</code>, which will be logged in
<code>solver_metadata</code>.</p>
<p>Additional arguments can be passed to the solver via <code>$solve(...)</code>
or <code>$eval(...)</code>. See the definition of <code><a href="generate.html">generate()</a></code> for a function that
outputs a valid solver that just passes inputs to ellmer Chat objects'
<code>$chat()</code> method in parallel.</p></dd>


<dt><code>scorer</code></dt>
<dd><p>A function that evaluates how well the solver's return value
approximates the corresponding elements of <code>dataset$target</code>. The function
should take in the <code>$get_samples()</code> slot of a Task object and return a list with
the following elements:</p><ul><li><p><code>score</code> - A vector of scores with length equal to <code>nrow(samples)</code>.
Built-in scorers return ordered factors with
levels <code>I</code> &lt; <code>P</code> (optionally) &lt; <code>C</code> (standing for "Incorrect", "Partially
Correct", and "Correct"). If your scorer returns this output type, the
package will automatically calculate metrics.</p></li>
</ul><p>Optionally:</p><ul><li><p><code>scorer_chat</code> - If your scorer makes use of ellmer, also include a list of
ellmer Chat objects that were used to score each result, also with
length <code>nrow(samples)</code>.</p></li>
<li><p><code>scorer_metadata</code> - Any intermediate results or other values that you'd
like to be stored in the persistent log. This should also have length
equal to <code>nrow(samples)</code>.</p></li>
</ul><p>Scorers will probably make use of <code>samples$input</code>, <code>samples$target</code>, and
<code>samples$result</code> specifically. See <a href="scorer_model.html">model-based scoring</a>
for examples.</p></dd>


<dt><code>metrics</code></dt>
<dd><p>A named list of functions that take in a vector of scores
(as in <code>task$get_samples()$score</code>) and output a single numeric value.</p></dd>


<dt><code>epochs</code></dt>
<dd><p>The number of times to repeat each sample. Evaluate each sample
multiple times to better quantify variation. Optional, defaults to <code>1L</code>.
The value of <code>epochs</code> supplied to <code>$eval()</code> or <code>$score()</code> will take
precedence over the value in <code>$new()</code>.</p></dd>


<dt><code>name</code></dt>
<dd><p>A name for the evaluation task. Defaults to
<code>deparse(substitute(dataset))</code>.</p></dd>


<dt><code>dir</code></dt>
<dd><p>Directory where logs should be stored.</p></dd>


</dl><p></p></div>
</div>

</div><p></p><hr><a id="method-Task-eval"></a><div class="section">
<h3 id="method-eval-">Method <code><a href="https://rdrr.io/r/base/eval.html" class="external-link">eval()</a></code><a class="anchor" aria-label="anchor" href="#method-eval-"></a></h3>
<p>Evaluates the task by running the solver, scorer, logging results, and
viewing (if interactive). This method works by calling <code>$solve()</code>,
<code>$score()</code>, <code>$log()</code>, and <code>$view()</code> in sequence.</p>
<p>The typical flow of LLM evaluation with vitals tends to involve first
calling <code>$new()</code> and then this method on the resulting object.</p><div class="section">
<h4 id="usage-1">Usage<a class="anchor" aria-label="anchor" href="#usage-1"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="va">...</span>, epochs <span class="op">=</span> <span class="cn">NULL</span>, view <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/interactive.html" class="external-link">interactive</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-1">Arguments<a class="anchor" aria-label="anchor" href="#arguments-1"></a></h4>
<p></p><div class="arguments"><dl><dt><code>...</code></dt>
<dd><p>Additional arguments passed to the solver and scorer functions.</p></dd>


<dt><code>epochs</code></dt>
<dd><p>The number of times to repeat each sample. Evaluate each sample
multiple times to better quantify variation. Optional, defaults to <code>1L</code>.
The value of <code>epochs</code> supplied to <code>$eval()</code> or <code>$score()</code> will take
precedence over the value in <code>$new()</code>.</p></dd>


<dt><code>view</code></dt>
<dd><p>Automatically open the viewer after evaluation (defaults to
TRUE if interactive, FALSE otherwise).</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns">Returns<a class="anchor" aria-label="anchor" href="#returns"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-get_samples"></a><div class="section">
<h3 id="method-get-samples-">Method <code>get_samples()</code><a class="anchor" aria-label="anchor" href="#method-get-samples-"></a></h3>
<p>The task's samples represent the evaluation in a data frame format.</p>
<p><code><a href="vitals_bind.html">vitals_bind()</a></code> row-binds the output of this
function called across several tasks.</p><div class="section">
<h4 id="usage-2">Usage<a class="anchor" aria-label="anchor" href="#usage-2"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">get_samples</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="returns-1">Returns<a class="anchor" aria-label="anchor" href="#returns-1"></a></h4>
<p>A tibble representing the evaluation. Based on the <code>dataset</code>,
<code>epochs</code> may duplicate rows, and the solver and scorer will append
columns to this data.</p>
</div>

</div><p></p><hr><a id="method-Task-solve"></a><div class="section">
<h3 id="method-solve-">Method <code><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve()</a></code><a class="anchor" aria-label="anchor" href="#method-solve-"></a></h3>
<p>Solve the task by running the solver</p><div class="section">
<h4 id="usage-3">Usage<a class="anchor" aria-label="anchor" href="#usage-3"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">solve</span><span class="op">(</span><span class="va">...</span>, epochs <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-2">Arguments<a class="anchor" aria-label="anchor" href="#arguments-2"></a></h4>
<p></p><div class="arguments"><dl><dt><code>...</code></dt>
<dd><p>Additional arguments passed to the solver function.</p></dd>


<dt><code>epochs</code></dt>
<dd><p>The number of times to repeat each sample. Evaluate each sample
multiple times to better quantify variation. Optional, defaults to <code>1L</code>.
The value of <code>epochs</code> supplied to <code>$eval()</code> or <code>$score()</code> will take
precedence over the value in <code>$new()</code>.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-2">Returns<a class="anchor" aria-label="anchor" href="#returns-2"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-score"></a><div class="section">
<h3 id="method-score-">Method <code>score()</code><a class="anchor" aria-label="anchor" href="#method-score-"></a></h3>
<p>Score the task by running the scorer and then applying metrics to
its results.</p><div class="section">
<h4 id="usage-4">Usage<a class="anchor" aria-label="anchor" href="#usage-4"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-3">Arguments<a class="anchor" aria-label="anchor" href="#arguments-3"></a></h4>
<p></p><div class="arguments"><dl><dt><code>...</code></dt>
<dd><p>Additional arguments passed to the scorer function.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-3">Returns<a class="anchor" aria-label="anchor" href="#returns-3"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-measure"></a><div class="section">
<h3 id="method-measure-">Method <code>measure()</code><a class="anchor" aria-label="anchor" href="#method-measure-"></a></h3>
<p>Applies metrics to a scored Task.</p><div class="section">
<h4 id="usage-5">Usage<a class="anchor" aria-label="anchor" href="#usage-5"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">measure</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-Task-log"></a><div class="section">
<h3 id="method-log-">Method <code><a href="https://rdrr.io/r/base/Log.html" class="external-link">log()</a></code><a class="anchor" aria-label="anchor" href="#method-log-"></a></h3>
<p>Log the task to a directory.</p>
<p>Note that, if an <code>VITALS_LOG_DIR</code> envvar is set, this will happen
automatically in <code>$eval()</code>.</p><div class="section">
<h4 id="usage-6">Usage<a class="anchor" aria-label="anchor" href="#usage-6"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">log</span><span class="op">(</span>dir <span class="op">=</span> <span class="fu"><a href="../reference/vitals_log_dir.html">vitals_log_dir</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-4">Arguments<a class="anchor" aria-label="anchor" href="#arguments-4"></a></h4>
<p></p><div class="arguments"><dl><dt><code>dir</code></dt>
<dd><p>The directory to write the log to.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-4">Returns<a class="anchor" aria-label="anchor" href="#returns-4"></a></h4>
<p>The path to the logged file, invisibly.</p>
</div>

</div><p></p><hr><a id="method-Task-view"></a><div class="section">
<h3 id="method-view-">Method <code><a href="https://tibble.tidyverse.org/reference/view.html" class="external-link">view()</a></code><a class="anchor" aria-label="anchor" href="#method-view-"></a></h3>
<p>View the task results in the Inspect log viewer</p><div class="section">
<h4 id="usage-7">Usage<a class="anchor" aria-label="anchor" href="#usage-7"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">view</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="returns-5">Returns<a class="anchor" aria-label="anchor" href="#returns-5"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-set_solver"></a><div class="section">
<h3 id="method-set-solver-">Method <code>set_solver()</code><a class="anchor" aria-label="anchor" href="#method-set-solver-"></a></h3>
<p>Set the solver function</p><div class="section">
<h4 id="usage-8">Usage<a class="anchor" aria-label="anchor" href="#usage-8"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">set_solver</span><span class="op">(</span><span class="va">solver</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-5">Arguments<a class="anchor" aria-label="anchor" href="#arguments-5"></a></h4>
<p></p><div class="arguments"><dl><dt><code>solver</code></dt>
<dd><p>A function that takes a vector of inputs from the
dataset's <code>input</code> column as its first argument and determines values
approximating <code>dataset$target</code>. Its return value must be a list with
the following elements:</p><ul><li><p><code>result</code> - A character vector of the final responses, with the same length
as <code>dataset$input</code>.</p></li>
<li><p><code>solver_chat</code> - A list of ellmer Chat objects that were used to solve
each input, also with the same length as <code>dataset$input</code>.</p></li>
</ul><p>Additional output elements can be included in a slot <code>solver_metadata</code> that
has the same length as <code>dataset$input</code>, which will be logged in
<code>solver_metadata</code>.</p>
<p>Additional arguments can be passed to the solver via <code>$solve(...)</code>
or <code>$eval(...)</code>. See the definition of <code><a href="generate.html">generate()</a></code> for a function that
outputs a valid solver that just passes inputs to ellmer Chat objects'
<code>$chat()</code> method in parallel.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-6">Returns<a class="anchor" aria-label="anchor" href="#returns-6"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-set_scorer"></a><div class="section">
<h3 id="method-set-scorer-">Method <code>set_scorer()</code><a class="anchor" aria-label="anchor" href="#method-set-scorer-"></a></h3>
<p>Set the scorer function</p><div class="section">
<h4 id="usage-9">Usage<a class="anchor" aria-label="anchor" href="#usage-9"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">set_scorer</span><span class="op">(</span><span class="va">scorer</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-6">Arguments<a class="anchor" aria-label="anchor" href="#arguments-6"></a></h4>
<p></p><div class="arguments"><dl><dt><code>scorer</code></dt>
<dd><p>A function that evaluates how well the solver's return value
approximates the corresponding elements of <code>dataset$target</code>. The function
should take in the <code>$get_samples()</code> slot of a Task object and return a list with
the following elements:</p><ul><li><p><code>score</code> - A vector of scores with length equal to <code>nrow(samples)</code>.
Built-in scorers return ordered factors with
levels <code>I</code> &lt; <code>P</code> (optionally) &lt; <code>C</code> (standing for "Incorrect", "Partially
Correct", and "Correct"). If your scorer returns this output type, the
package will automatically calculate metrics.</p></li>
</ul><p>Optionally:</p><ul><li><p><code>scorer_chat</code> - If your scorer makes use of ellmer, also include a list of
ellmer Chat objects that were used to score each result, also with
length <code>nrow(samples)</code>.</p></li>
<li><p><code>scorer_metadata</code> - Any intermediate results or other values that you'd
like to be stored in the persistent log. This should also have length
equal to <code>nrow(samples)</code>.</p></li>
</ul><p>Scorers will probably make use of <code>samples$input</code>, <code>samples$target</code>, and
<code>samples$result</code> specifically. See <a href="scorer_model.html">model-based scoring</a>
for examples.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-7">Returns<a class="anchor" aria-label="anchor" href="#returns-7"></a></h4>
<p>The Task object (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-set_metrics"></a><div class="section">
<h3 id="method-set-metrics-">Method <code>set_metrics()</code><a class="anchor" aria-label="anchor" href="#method-set-metrics-"></a></h3>
<p>Set the metrics that will be applied in <code>$measure()</code> (and thus <code>$eval()</code>).</p><div class="section">
<h4 id="usage-10">Usage<a class="anchor" aria-label="anchor" href="#usage-10"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">set_metrics</span><span class="op">(</span><span class="va">metrics</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-7">Arguments<a class="anchor" aria-label="anchor" href="#arguments-7"></a></h4>
<p></p><div class="arguments"><dl><dt><code>metrics</code></dt>
<dd><p>A named list of functions that take in a vector of scores
(as in <code>task$get_samples()$score</code>) and output a single numeric value.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns-8">Returns<a class="anchor" aria-label="anchor" href="#returns-8"></a></h4>
<p>The Task (invisibly)</p>
</div>

</div><p></p><hr><a id="method-Task-get_cost"></a><div class="section">
<h3 id="method-get-cost-">Method <code>get_cost()</code><a class="anchor" aria-label="anchor" href="#method-get-cost-"></a></h3>
<p>The cost of this eval
This is a wrapper around ellmer's <code>$token_usage()</code> function.
That function is called at the beginning and end of each call to
<code>$solve()</code> and <code>$score()</code>; this function returns the cost inferred
by taking the differences in values of <code>$token_usage()</code> over time.</p><div class="section">
<h4 id="usage-11">Usage<a class="anchor" aria-label="anchor" href="#usage-11"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">get_cost</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="returns-9">Returns<a class="anchor" aria-label="anchor" href="#returns-9"></a></h4>
<p>The sum of the cost of solving and scoring the evaluation.
The sum only includes the cost from the most recent runs of the
solver and scorer.</p>
</div>

</div><p></p><hr><a id="method-Task-clone"></a><div class="section">
<h3 id="method-clone-">Method <code>clone()</code><a class="anchor" aria-label="anchor" href="#method-clone-"></a></h3>
<p>The objects of this class are cloneable with this method.</p><div class="section">
<h4 id="usage-12">Usage<a class="anchor" aria-label="anchor" href="#usage-12"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">Task</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span>deep <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-8">Arguments<a class="anchor" aria-label="anchor" href="#arguments-8"></a></h4>
<p></p><div class="arguments"><dl><dt><code>deep</code></dt>
<dd><p>Whether to make a deep clone.</p></dd>


</dl><p></p></div>
</div>

</div>

    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/identical.html" class="external-link">identical</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Sys.getenv.html" class="external-link">Sys.getenv</a></span><span class="op">(</span><span class="st">"ANTHROPIC_API_KEY"</span><span class="op">)</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ellmer.tidyverse.org" class="external-link">ellmer</a></span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tibble.tidyverse.org/" class="external-link">tibble</a></span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="va">simple_addition</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    input <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"What's 2+2?"</span>, <span class="st">"What's 2+3?"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    target <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"4"</span>, <span class="st">"5"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># create a new Task</span></span></span>
<span class="r-in"><span>  <span class="va">tsk</span> <span class="op">&lt;-</span> <span class="va">Task</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span></span>
<span class="r-in"><span>    dataset <span class="op">=</span> <span class="va">simple_addition</span>,</span></span>
<span class="r-in"><span>    solver <span class="op">=</span> <span class="fu"><a href="generate.html">generate</a></span><span class="op">(</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_anthropic.html" class="external-link">chat_anthropic</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"claude-3-7-sonnet-latest"</span><span class="op">)</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    scorer <span class="op">=</span> <span class="fu"><a href="scorer_model.html">model_graded_qa</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># evaluate the task (runs solver and scorer) and opens</span></span></span>
<span class="r-in"><span>  <span class="co"># the results in the Inspect log viewer (if interactive)</span></span></span>
<span class="r-in"><span>  <span class="va">tsk</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Solving</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> [working] (0 + 0) -&gt; 1 -&gt; 1 | <span style="color: #00BB00;">■■■■■■■■■■■■■■■■                </span>  50%</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> [working] (0 + 0) -&gt; 0 -&gt; 2 | <span style="color: #00BB00;">■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ </span> 100%</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Solving</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BB00;">✔</span> Solving <span style="color: #B2B2B2;">[2.9s]</span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Scoring</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> [working] (0 + 0) -&gt; 1 -&gt; 1 | <span style="color: #00BB00;">■■■■■■■■■■■■■■■■                </span>  50%</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> [working] (0 + 0) -&gt; 0 -&gt; 2 | <span style="color: #00BB00;">■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ </span> 100%</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Scoring</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BB00;">✔</span> Scoring <span style="color: #B2B2B2;">[14ms]</span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


   </div>
  <footer><div class="container">
  <div class="pkgdown-footer-left">
  <p>Developed by Simon Couch, <a href="https://www.posit.co" class="external-link"><img src="https://www.tidyverse.org/posit-logo.svg" alt="Posit" height="16" width="62" style="margin-bottom: 3px;"></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

  </div></footer></body></html>

