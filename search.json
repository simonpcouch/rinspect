[{"path":[]},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@posit.co. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://simonpcouch.github.io/rinspect/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla‚Äôs code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://simonpcouch.github.io/rinspect/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 rinspect authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://simonpcouch.github.io/rinspect/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Simon Couch. Author, maintainer. Posit Software, PBC. Copyright holder, funder.","code":""},{"path":"https://simonpcouch.github.io/rinspect/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Couch S (2025). rinspect: Large Language Model Evaluation R. R package version 0.0.0.9000, https://simonpcouch.github.io/rinspect/, https://github.com/simonpcouch/rinspect.","code":"@Manual{,   title = {rinspect: Large Language Model Evaluation for R},   author = {Simon Couch},   year = {2025},   note = {R package version 0.0.0.9000,     https://simonpcouch.github.io/rinspect/},   url = {https://github.com/simonpcouch/rinspect}, }"},{"path":"https://simonpcouch.github.io/rinspect/index.html","id":"rinspect","dir":"","previous_headings":"","what":"Large Language Model Evaluation for R","title":"Large Language Model Evaluation for R","text":"rinspect framework large language model evaluation R. ‚Äôs specifically aimed ellmer users want measure effectiveness LLM-based apps. package R port widely adopted Python framework Inspect. package doesn‚Äôt integrate Inspect directly, allows users interface Inspect Log Viewer provides -ramp transition Inspect need writing evaluation logs file format. Important üöß construction! üöß rinspect highly experimental much documentation aspirational.","code":""},{"path":"https://simonpcouch.github.io/rinspect/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Large Language Model Evaluation for R","text":"can install developmental version rinspect using:","code":"pak::pak(\"simonpcouch/rinspect\")"},{"path":"https://simonpcouch.github.io/rinspect/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Large Language Model Evaluation for R","text":"Inspect based three core concepts: datasets, solvers, scorers. rinspect, objects act tasks. Datasets set labelled samples input prompt target either literal value(s) grading guidance. Situate dataset inside task task_create(): Solvers evaluate input dataset produce final result (hopefully) resembling target. simplest example solver plain ellmer chat‚Äîevaluate solver task task_solve(): Scorers evaluate final output solvers. may use text comparisons, model grading, custom schemes. Score solver output using task_score(): task scored, ‚Äôs ready explore interactively Inspect Log Viewer:","code":"library(rinspect) library(ellmer) library(tibble) simple_addition <- tibble(   input = c(\"What's 2+2?\", \"What's 2+3?\", \"What's 2+4?\"),   target = c(\"4\", \"5\", \"6\") )  tsk <- task_create(dataset = simple_addition) tsk #> # Evaluation task simple_addition. #> # A tibble: 3 √ó 3 #>   input       target    id #> * <chr>       <chr>  <int> #> 1 What's 2+2? 4          1 #> 2 What's 2+3? 5          2 #> 3 What's 2+4? 6          3 tsk <- task_solve(tsk, solver = chat_claude()) #> Solving ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                       33% | ETA:  2s #> Solving ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†             67% | ETA:  1s #> Solving ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†  100% | ETA:  0s tsk #> # Evaluation task simple_addition. #> # A tibble: 3 √ó 5 #>   input       target    id output  solver #> * <chr>       <chr>  <int> <chr>   <list> #> 1 What's 2+2? 4          1 2+2=4   <Chat> #> 2 What's 2+3? 5          2 2+3 = 5 <Chat> #> 3 What's 2+4? 6          3 2+4 = 6 <Chat> tsk <- task_score(tsk, scorer = model_graded_qa()) #> Scoring ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                       33% | ETA:  5s #> Scoring ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†  100% | ETA:  0s tsk #> # Evaluation task simple_addition. #> # A tibble: 3 √ó 7 #>   input       target    id output  solver score scorer #> * <chr>       <chr>  <int> <chr>   <list> <dbl> <list> #> 1 What's 2+2? 4          1 2+2=4   <Chat>     1 <Chat> #> 2 What's 2+3? 5          2 2+3 = 5 <Chat>     1 <Chat> #> 3 What's 2+4? 6          3 2+4 = 6 <Chat>     1 <Chat> inspect_view(tsk)"},{"path":"https://simonpcouch.github.io/rinspect/reference/eval_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Read and write evaluation logs ‚Äî eval_log","title":"Read and write evaluation logs ‚Äî eval_log","text":"Utilities reading writing evaluation logs. utilities support INSPECT_LOG_DIR environment variable, sets default directory write logs .","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/eval_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read and write evaluation logs ‚Äî eval_log","text":"","code":"eval_log_read(x)  eval_log_write(x = eval_log_new(), dir = eval_log_dir())  eval_log_dir()  eval_log_dir_set(dir)"},{"path":"https://simonpcouch.github.io/rinspect/reference/eval_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read and write evaluation logs ‚Äî eval_log","text":"x eval_log_read(), path log file read. eval_log_write(), evaluation log object write disk. dir Directory logs stored.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/eval_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read and write evaluation logs ‚Äî eval_log","text":"","code":"file <-   system.file(     \"logs/2025-02-08T15-51-00-06-00_simple-arithmetic_o3cKtmsvqQtmXGZhvfDrKB.json\",      package = \"rinspect\"   )  example_eval_log <- eval_log_read(file)  example_eval_log #> ‚îÄ‚îÄ An eval log. ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"},{"path":"https://simonpcouch.github.io/rinspect/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Solver: generate output ‚Äî generate","title":"Solver: generate output ‚Äî generate","text":"Solvers evaluate input dataset produce result aimed replicating target. generate() basic solver rinspect, just calls model input collects output.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solver: generate output ‚Äî generate","text":"","code":"generate(chat = ellmer::chat_claude())"},{"path":"https://simonpcouch.github.io/rinspect/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solver: generate output ‚Äî generate","text":"chat ellmer chat.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solver: generate output ‚Äî generate","text":"function takes input parameter optional chat parameter, returning named list containing final result well ellmer chat object generated .","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solver: generate output ‚Äî generate","text":"","code":"if (interactive()) {   generate() }"},{"path":"https://simonpcouch.github.io/rinspect/reference/inspect_view.html","id":null,"dir":"Reference","previous_headings":"","what":"The Inspect Log Viewer ‚Äî inspect_view","title":"The Inspect Log Viewer ‚Äî inspect_view","text":"Inspect Log Viewer","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/inspect_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Inspect Log Viewer ‚Äî inspect_view","text":"","code":"inspect_view(x, host = \"127.0.0.1\", port = 7576)  # S3 method for class 'character' inspect_view(x, host = \"127.0.0.1\", port = 7576)  # S3 method for class 'task' inspect_view(x, host = \"127.0.0.1\", port = 7576)"},{"path":"https://simonpcouch.github.io/rinspect/reference/inspect_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Inspect Log Viewer ‚Äî inspect_view","text":"x Either path directory containing task eval log task . task, function log task temporary directory open directory viewer. host Host serve . Defaults \"127.0.0.1\", port Port serve . Defaults 7576, one greater Python implementation.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/inspect_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Inspect Log Viewer ‚Äî inspect_view","text":"","code":"if (!identical(Sys.getenv(\"ANTHROPIC_API_KEY\"), \"\")) {   library(ellmer)   library(tibble)    simple_addition <- tibble(     input = c(\"What's 2+2?\", \"What's 2+3?\"),     target = c(\"4\", \"5\")   )    tsk <- task_create(dataset = simple_addition)   tsk    tsk <- task_solve(tsk, solver = chat_claude())   tsk    tsk <- task_score(tsk, scorer = model_graded_qa())   tsk    if (interactive()) {     inspect_view(tsk)   } }"},{"path":"https://simonpcouch.github.io/rinspect/reference/rinspect-package.html","id":null,"dir":"Reference","previous_headings":"","what":"rinspect: Large Language Model Evaluation for R ‚Äî rinspect-package","title":"rinspect: Large Language Model Evaluation for R ‚Äî rinspect-package","text":"port 'Inspect', widely adopted 'Python' framework large language model evaluation. Specifically aimed 'ellmer' users want measure effectiveness LLM-based apps, package includes facilities prompt engineering, tool usage, multi-turn dialog, model graded evaluations.","code":""},{"path":[]},{"path":"https://simonpcouch.github.io/rinspect/reference/rinspect-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"rinspect: Large Language Model Evaluation for R ‚Äî rinspect-package","text":"Maintainer: Simon Couch simon.couch@posit.co (ORCID) contributors: Posit Software, PBC [copyright holder, funder]","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/scorer_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based scoring ‚Äî scorer_model","title":"Model-based scoring ‚Äî scorer_model","text":"Model-based scoring makes use model score output solver. model_graded_qa() scores well solver answers question/answer task. model_graded_fact() determines whether solver includes given fact response. two scorers quite similar implementation, use different default template evaluate correctness.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/scorer_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based scoring ‚Äî scorer_model","text":"","code":"model_graded_qa(   template = NULL,   instructions = NULL,   grade_pattern = \"(?i)GRADE\\\\s*:\\\\s*([CPI])(.*)$\",   partial_credit = FALSE,   chat = ellmer::chat_claude() )  model_graded_fact(   template = NULL,   instructions = NULL,   grade_pattern = \"(?i)GRADE\\\\s*:\\\\s*([CPI])(.*)$\",   partial_credit = FALSE,   chat = ellmer::chat_claude() )"},{"path":"https://simonpcouch.github.io/rinspect/reference/scorer_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based scoring ‚Äî scorer_model","text":"template Grading template use‚Äìglue() string take substitutions input, answer, criterion, instructions. instructions Grading instructions. grade_pattern regex pattern extract final grade judge model's response. partial_credit Whether allow partial credit. chat ellmer chat used grade model output.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/scorer_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based scoring ‚Äî scorer_model","text":"function grade model responses according given instructions. can passed directly task_score().","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/scorer_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based scoring ‚Äî scorer_model","text":"","code":"# Quality assurance ----------------------------- if (!identical(\"ANTHROPIC_API_KEY\", \"\")) {   library(ellmer)   library(tibble)    simple_addition <- tibble(     input = c(\"What's 2+2?\", \"What's 2+3?\"),     target = c(\"4\", \"5\")   )    tsk <- task_create(dataset = simple_addition)   tsk    tsk <- task_solve(tsk, solver = chat_claude())   tsk    tsk <- task_score(tsk, scorer = model_graded_qa())   tsk    if (interactive()) {     inspect_view(tsk)   } } #> Error in anthropic_key(): Can't find env var `ANTHROPIC_API_KEY`.  # Factual response ------------------------------- if (!identical(\"ANTHROPIC_API_KEY\", \"\")) {   library(ellmer)   library(tibble)    r_history <- tibble(     input = c(       \"Who created the R programming language?\",       \"In what year was version 1.0 of R released?\"     ),     target = c(\"Ross Ihaka and Robert Gentleman.\", \"2000.\")   )    tsk <- task_create(dataset = r_history)   tsk    tsk <- task_solve(tsk, solver = chat_claude())   tsk    tsk <- task_score(tsk, scorer = model_graded_fact())   tsk    if (interactive()) {     inspect_view(tsk)   } } #> Error in anthropic_key(): Can't find env var `ANTHROPIC_API_KEY`."},{"path":"https://simonpcouch.github.io/rinspect/reference/task.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation tasks ‚Äî task","title":"Evaluation tasks ‚Äî task","text":"Evaluation tasks provide flexible data structure evaluating LLM-based tools. Datasets contain set labelled samples. Datasets just tibble columns input target, input prompt target either literal value(s) grading guidance. Situate datasets inside task task_create(). Solvers evaluate input dataset produce final result. simplest solver just ellmer chat‚Äîevaluate task solver using task_solve(). Scorers evaluate final output solvers. may use text comparisons, model grading (like model_graded_qa()), custom schemes. Score solver results using task_score().","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/task.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation tasks ‚Äî task","text":"","code":"task_create(dataset, name = deparse(substitute(dataset)), dir = eval_log_dir())  task_solve(task, solver, epochs = 1L)  task_score(task, scorer)  task_log(task, time_start = Sys.time(), dir = attr(res, \"dir\"))"},{"path":"https://simonpcouch.github.io/rinspect/reference/task.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluation tasks ‚Äî task","text":"dataset tibble , minimally, columns input target. name name evaluation task. Defaults deparse(substitute(dataset)). dir directory write evaluation logs . task evaluation task created task_create(). solver function takes element dataset$input input determines value approximating dataset$target. return value list elements result (final response) chat (ellmer chat used solve problem, list ). , just supply ellmer chat. epochs number times repeat sample. Evaluate sample multiple times measure variation. Optional, defaults 1L. scorer function evaluates well solver's return value approximates corresponding elements dataset$target. See model-based scoring examples. time_start TODO: remove.","code":""},{"path":"https://simonpcouch.github.io/rinspect/reference/task.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluation tasks ‚Äî task","text":"functions return task, subclass tibble. task_create() appends column id. task_solve() appends columns output solver. task_score() appends columns score scorer.","code":""},{"path":[]},{"path":"https://simonpcouch.github.io/rinspect/reference/task.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluation tasks ‚Äî task","text":"","code":"if (!identical(Sys.getenv(\"ANTHROPIC_API_KEY\"), \"\")) {   library(ellmer)   library(tibble)    simple_addition <- tibble(     input = c(\"What's 2+2?\", \"What's 2+3?\"),     target = c(\"4\", \"5\")   )    tsk <- task_create(dataset = simple_addition)   tsk    tsk <- task_solve(tsk, solver = chat_claude())   tsk    tsk <- task_score(tsk, scorer = model_graded_qa())   tsk    if (interactive()) {     inspect_view(tsk)   } }"}]
